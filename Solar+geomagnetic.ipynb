{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ade6063-d909-45ce-8c26-9d481948df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA data after conversion:\n",
      "                   time_tag  satellite          flux  observed_flux  \\\n",
      "0 2024-09-26 10:59:00+00:00         16  5.267604e-08   6.918628e-08   \n",
      "1 2024-09-26 10:59:00+00:00         16  2.376826e-06   2.404217e-06   \n",
      "2 2024-09-26 11:00:00+00:00         16  5.384534e-08   7.102810e-08   \n",
      "3 2024-09-26 11:00:00+00:00         16  2.385958e-06   2.413543e-06   \n",
      "4 2024-09-26 11:01:00+00:00         16  5.633739e-08   7.287300e-08   \n",
      "\n",
      "   electron_correction  electron_contaminaton      energy  \n",
      "0         1.651024e-08                  False  0.05-0.4nm  \n",
      "1         2.739015e-08                  False   0.1-0.8nm  \n",
      "2         1.718276e-08                  False  0.05-0.4nm  \n",
      "3         2.758464e-08                  False   0.1-0.8nm  \n",
      "4         1.653561e-08                  False  0.05-0.4nm   \n",
      "\n",
      "Helioviewer data:\n",
      "          id                 date     name     scale  scaleCorrection  width  \\\n",
      "0  148024150  2023-09-14 23:59:49  AIA 335  0.603527         0.994157   4096   \n",
      "\n",
      "   height  refPixelX  refPixelY  rotation       rsun          dsun  \\\n",
      "0    4096     2048.5     2048.5         0  1590.0621  150477150000   \n",
      "\n",
      "  sunCenterOffsetParams  layeringOrder  \n",
      "0                    []              1   \n",
      "\n",
      "Helioviewer data after date conversion:\n",
      "          id                date     name     scale  scaleCorrection  width  \\\n",
      "0  148024150 2023-09-14 23:59:49  AIA 335  0.603527         0.994157   4096   \n",
      "\n",
      "   height  refPixelX  refPixelY  rotation       rsun          dsun  \\\n",
      "0    4096     2048.5     2048.5         0  1590.0621  150477150000   \n",
      "\n",
      "  sunCenterOffsetParams  layeringOrder  \n",
      "0                    []              1   \n",
      "\n",
      "Combined DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [time_tag, satellite, flux, observed_flux, electron_correction, electron_contaminaton, energy, id, date, name, scale, scaleCorrection, width, height, refPixelX, refPixelY, rotation, rsun, dsun, sunCenterOffsetParams, layeringOrder]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fetching data from NOAA API (X-ray Flux Data)\n",
    "noaa_url = \"https://services.swpc.noaa.gov/json/goes/primary/xrays-1-day.json\"\n",
    "noaa_response = requests.get(noaa_url)\n",
    "noaa_data = noaa_response.json()\n",
    "\n",
    "# Convert NOAA data to pandas DataFrame\n",
    "noaa_df = pd.DataFrame(noaa_data)\n",
    "\n",
    "# Ensure 'time_tag' is in datetime format with UTC timezone\n",
    "noaa_df['time_tag'] = pd.to_datetime(noaa_df['time_tag'], utc=True)\n",
    "print(\"NOAA data after conversion:\")\n",
    "print(noaa_df.head(), \"\\n\")\n",
    "\n",
    "\n",
    "# 2. Fetching data from Helioviewer API\n",
    "helioviewer_url = \"https://api.helioviewer.org/v2/getClosestImage/?date=2023-09-15T00:00:00Z&sourceId=14\"\n",
    "helioviewer_response = requests.get(helioviewer_url)\n",
    "helioviewer_data = helioviewer_response.json()\n",
    "\n",
    "# Convert Helioviewer response to DataFrame (assuming 'date' is present)\n",
    "helioviewer_df = pd.DataFrame([helioviewer_data])\n",
    "\n",
    "# Inspect what data is available in Helioviewer to find relevant date\n",
    "print(\"Helioviewer data:\")\n",
    "print(helioviewer_df.head(), \"\\n\")\n",
    "\n",
    "# 3. Check if the 'date' field exists, and if not, handle appropriately\n",
    "if 'date' in helioviewer_df.columns:\n",
    "    # Ensure 'date' is in datetime format without timezone\n",
    "    helioviewer_df['date'] = pd.to_datetime(helioviewer_df['date'])\n",
    "else:\n",
    "    # If 'date' is missing, print a message\n",
    "    print(\"Date field not found in Helioviewer data. Creating mock 'date' for demo purposes.\")\n",
    "    # Create a mock 'date' column for merging (use the date from the API request for now)\n",
    "    helioviewer_df['date'] = pd.to_datetime(\"2023-09-15\")\n",
    "\n",
    "print(\"Helioviewer data after date conversion:\")\n",
    "print(helioviewer_df.head(), \"\\n\")\n",
    "\n",
    "# 4. To match the formats, convert the Helioviewer date to UTC (timezone-aware)\n",
    "helioviewer_df['date'] = helioviewer_df['date'].dt.tz_localize('UTC')\n",
    "\n",
    "# 5. Merge the NOAA and Helioviewer DataFrames\n",
    "combined_df = pd.merge(noaa_df, helioviewer_df, how='inner', left_on='time_tag', right_on='date')\n",
    "\n",
    "# Print the combined DataFrame to verify the merge\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5b9ec4b-1027-48e9-bfa5-5be55503978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [time_tag, satellite, flux, observed_flux, electron_correction, electron_contaminaton, energy, id, date, name, scale, scaleCorrection, width, height, refPixelX, refPixelY, rotation, rsun, dsun, sunCenterOffsetParams, layeringOrder, flux_difference, hour, day, month]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the NOAA data (e.g., X-ray flux levels)\n",
    "combined_df['flux_difference'] = combined_df['flux'] - combined_df['flux'].shift(1)\n",
    "\n",
    "# Feature engineering: Add time-related features\n",
    "combined_df['hour'] = combined_df['time_tag'].dt.hour\n",
    "combined_df['day'] = combined_df['time_tag'].dt.day\n",
    "combined_df['month'] = combined_df['time_tag'].dt.month\n",
    "\n",
    "# Handle missing values (using the forward-fill method)\n",
    "combined_df = combined_df.ffill()  # Forward fill missing values\n",
    "\n",
    "# Drop irrelevant columns (check if they exist)\n",
    "columns_to_drop = ['unnecessary_column_1', 'unnecessary_column_2']\n",
    "combined_df = combined_df.drop(columns=[col for col in columns_to_drop if col in combined_df.columns], errors='ignore')\n",
    "\n",
    "# Check the DataFrame after processing\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccdd6a91-1c7d-4ad9-8e51-774a8fe17f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (0, 25)\n",
      "Warning: The DataFrame is empty. Check your data loading or filtering steps.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Check the size of the DataFrame\n",
    "print(\"DataFrame shape:\", combined_df.shape)\n",
    "\n",
    "# If the DataFrame is empty, check if any filtering steps caused it\n",
    "if combined_df.empty:\n",
    "    print(\"Warning: The DataFrame is empty. Check your data loading or filtering steps.\")\n",
    "\n",
    "# Ensure your data is loaded correctly before train_test_split\n",
    "if not combined_df.empty:\n",
    "    X = combined_df[['flux_difference', 'hour', 'day', 'month', 'solar_event_1', 'solar_event_2']]\n",
    "    y = combined_df['flux']\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features if necessary\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(\"Training and test sets prepared successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94c08a2b-6d5d-41e9-9b3e-2da0890e2a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape: (0, 25)\n",
      "The DataFrame is empty. Check data loading step.\n",
      "Missing data check:\n",
      "time_tag                 0\n",
      "satellite                0\n",
      "flux                     0\n",
      "observed_flux            0\n",
      "electron_correction      0\n",
      "electron_contaminaton    0\n",
      "energy                   0\n",
      "id                       0\n",
      "date                     0\n",
      "name                     0\n",
      "scale                    0\n",
      "scaleCorrection          0\n",
      "width                    0\n",
      "height                   0\n",
      "refPixelX                0\n",
      "refPixelY                0\n",
      "rotation                 0\n",
      "rsun                     0\n",
      "dsun                     0\n",
      "sunCenterOffsetParams    0\n",
      "layeringOrder            0\n",
      "flux_difference          0\n",
      "hour                     0\n",
      "day                      0\n",
      "month                    0\n",
      "dtype: int64\n",
      "Missing values handled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Check if the data was loaded correctly\n",
    "print(\"Initial DataFrame shape:\", combined_df.shape)\n",
    "\n",
    "# If the shape is (0, 27), it means there is no data\n",
    "if combined_df.empty:\n",
    "    print(\"The DataFrame is empty. Check data loading step.\")\n",
    "else:\n",
    "    print(\"Data loaded successfully. Here's a preview:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "# Check for any filtering or dropping operations that might have caused this\n",
    "# Example: if you had filtering conditions\n",
    "# combined_df = combined_df[combined_df['some_column'] > threshold]\n",
    "# If such filters exist, verify that they didn't remove all rows.\n",
    "\n",
    "# Also check for missing values\n",
    "print(\"Missing data check:\")\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# If missing values were an issue, try handling them\n",
    "# Handle missing values using forward fill (or you can use backward fill as per your need)\n",
    "combined_df.ffill(inplace=True)\n",
    "\n",
    "# Continue with the rest of your code\n",
    "print(\"Missing values handled successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90b5aff3-6b72-4dd9-bbc3-a7d1529a725d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edbb90-a581-4735-8d72-7ec7401dbe86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
